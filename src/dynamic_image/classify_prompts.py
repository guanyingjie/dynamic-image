"""
ä½¿ç”¨ Gemini API å¯¹ Midjourney è§†é¢‘ prompts è¿›è¡Œåˆ†ç±»
"""
import json
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List
import google.generativeai as genai
from dotenv import load_dotenv


# é…ç½®æ–‡ä»¶è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent
PROMPT_FILE = PROJECT_ROOT / "prompt.md"
SOURCE_JSON = PROJECT_ROOT / "images" / "source.json"
RESULT_DIR = PROJECT_ROOT / "result"

# åŠ è½½ .env æ–‡ä»¶
load_dotenv(PROJECT_ROOT / ".env")


def load_classification_prompt() -> str:
    """åŠ è½½åˆ†ç±»æç¤ºè¯"""
    try:
        with open(PROMPT_FILE, 'r', encoding='utf-8') as f:
            prompt_content = f.read()
        print(f"âœ… æˆåŠŸåŠ è½½åˆ†ç±»æç¤ºè¯: {PROMPT_FILE}")
        return prompt_content
    except FileNotFoundError:
        print(f"âŒ æ‰¾ä¸åˆ°æç¤ºè¯æ–‡ä»¶: {PROMPT_FILE}")
        raise
    except Exception as e:
        print(f"âŒ åŠ è½½æç¤ºè¯å¤±è´¥: {e}")
        raise


def load_source_data() -> List[Dict]:
    """åŠ è½½æºæ•°æ® JSON"""
    try:
        with open(SOURCE_JSON, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"âœ… æˆåŠŸåŠ è½½æºæ•°æ®: {len(data)} æ¡è®°å½•")
        return data
    except FileNotFoundError:
        print(f"âŒ æ‰¾ä¸åˆ°æºæ•°æ®æ–‡ä»¶: {SOURCE_JSON}")
        raise
    except json.JSONDecodeError as e:
        print(f"âŒ JSON è§£æé”™è¯¯: {e}")
        raise


def prepare_input_for_gemini(data: List[Dict]) -> str:
    """å‡†å¤‡å‘é€ç»™ Gemini çš„è¾“å…¥æ•°æ®ï¼ˆç®€åŒ–æ ¼å¼ï¼‰"""
    simplified_data = []
    
    for item in data:
        video_id = item.get('id')
        prompt_obj = item.get('prompt', {})
        decoded_prompts = prompt_obj.get('decodedPrompt', [])
        
        if decoded_prompts and len(decoded_prompts) > 0:
            content = decoded_prompts[0].get('content', '')
            simplified_data.append({
                "id": video_id,
                "prompt": {
                    "decodedPrompt": [
                        {"content": content}
                    ]
                }
            })
    
    return json.dumps(simplified_data, ensure_ascii=False, indent=2)


def init_gemini_api(api_key: str = None):
    """åˆå§‹åŒ– Gemini API"""
    if api_key is None:
        api_key = os.getenv("GEMINI_API_KEY")
        if api_key is None:
            raise ValueError(
                "è¯·è®¾ç½®ç¯å¢ƒå˜é‡ GEMINI_API_KEY\n"
                "ä¾‹å¦‚: export GEMINI_API_KEY='your-api-key'"
            )
    
    genai.configure(api_key=api_key)
    print(f"âœ… Gemini API åˆå§‹åŒ–å®Œæˆ")


def classify_with_gemini(
    classification_prompt: str,
    input_data: str,
    model_name: str = "gemini-2.0-flash-exp",
    temperature: float = 0.1
) -> Dict:
    """ä½¿ç”¨ Gemini æ¨¡å‹è¿›è¡Œåˆ†ç±»"""
    
    print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_name}")
    print(f"ğŸ“Š è¾“å…¥æ•°æ®é•¿åº¦: {len(input_data)} å­—ç¬¦")
    
    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    model = genai.GenerativeModel(
        model_name=model_name,
        generation_config={
            "temperature": temperature,
            "max_output_tokens": 8192,
            "response_mime_type": "application/json"
        }
    )
    
    # æ„å»ºå®Œæ•´çš„æç¤ºè¯
    full_prompt = f"""
{classification_prompt}

# Input Data (è¾“å…¥æ•°æ®)
è¯·åˆ†æä»¥ä¸‹ JSON æ•°æ®å¹¶æŒ‰ç…§ä¸Šè¿°æ ‡å‡†è¿›è¡Œåˆ†ç±»ï¼š

```json
{input_data}
```

è¯·ç›´æ¥è¾“å‡ºåˆ†ç±»ç»“æœçš„ JSONï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—è¯´æ˜ã€‚
"""
    
    print("ğŸš€ æ­£åœ¨è°ƒç”¨ Gemini æ¨¡å‹è¿›è¡Œåˆ†ç±»...")
    print("â³ è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·ç¨å€™...")
    
    try:
        # è°ƒç”¨æ¨¡å‹
        response = model.generate_content(full_prompt)
        
        print("âœ… Gemini æ¨¡å‹è¿”å›æˆåŠŸ")
        
        # è·å–è¿”å›æ–‡æœ¬
        result_text = response.text
        
        # æ¸…ç†å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
        result_text = result_text.strip()
        if result_text.startswith("```json"):
            result_text = result_text[7:]
        if result_text.startswith("```"):
            result_text = result_text[3:]
        if result_text.endswith("```"):
            result_text = result_text[:-3]
        result_text = result_text.strip()
        
        # ä¿å­˜åŸå§‹è¿”å›ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        RESULT_DIR.mkdir(exist_ok=True)
        debug_file = RESULT_DIR / "debug_response.txt"
        with open(debug_file, 'w', encoding='utf-8') as f:
            f.write(result_text)
        print(f"ğŸ“ åŸå§‹è¿”å›å·²ä¿å­˜åˆ°: {debug_file}")
        
        # è§£æ JSON
        try:
            result_json = json.loads(result_text)
        except json.JSONDecodeError as e:
            print(f"âŒ JSON è§£æé”™è¯¯: {e}")
            print(f"ğŸ“„ è¿”å›å†…å®¹é•¿åº¦: {len(result_text)} å­—ç¬¦")
            print(f"ğŸ“„ è¿”å›å†…å®¹çš„å‰ 500 å­—ç¬¦:")
            print(result_text[:500])
            print(f"\nğŸ“„ è¿”å›å†…å®¹çš„å 500 å­—ç¬¦:")
            print(result_text[-500:])
            print(f"\nğŸ’¡ å®Œæ•´å†…å®¹å·²ä¿å­˜åˆ°: {debug_file}")
            raise
        
        return result_json
    
    except Exception as e:
        print(f"âŒ è°ƒç”¨ Gemini æ¨¡å‹å¤±è´¥: {e}")
        raise


def merge_classification_results(results: List[Dict]) -> Dict:
    """åˆå¹¶å¤šä¸ªåˆ†ç±»ç»“æœ"""
    merged = {}
    
    for result in results:
        for category, items in result.items():
            if category not in merged:
                merged[category] = []
            merged[category].extend(items)
    
    return merged


def save_result(result: Dict, filename: str = None):
    """ä¿å­˜åˆ†ç±»ç»“æœåˆ° result ç›®å½•"""
    # åˆ›å»º result ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    RESULT_DIR.mkdir(exist_ok=True)
    
    # ç”Ÿæˆæ–‡ä»¶åï¼ˆå¦‚æœæœªæŒ‡å®šï¼‰
    if filename is None:
        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        filename = f"classification_result_{timestamp}.json"
    
    output_path = RESULT_DIR / filename
    
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… åˆ†ç±»ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š åˆ†ç±»ç»Ÿè®¡:")
        total_items = 0
        for category, items in result.items():
            count = len(items)
            total_items += count
            print(f"  â€¢ {category}: {count} ä¸ª")
        print(f"\n  æ€»è®¡: {total_items} ä¸ªæ¡ç›®è¢«åˆ†ç±»")
    
    except Exception as e:
        print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
        raise


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ğŸ¨ Midjourney Prompt æ™ºèƒ½åˆ†ç±»ç³»ç»Ÿ (Powered by Gemini)")
    print("=" * 80)
    
    # é…ç½®æ‰¹å¤„ç†å‚æ•°
    BATCH_SIZE = 100  # æ¯æ‰¹å¤„ç†çš„æ•°æ®é‡
    
    try:
        # 1. åˆå§‹åŒ– Gemini API
        print("\nğŸ”‘ æ­¥éª¤ 1: åˆå§‹åŒ– Gemini API")
        api_key = os.getenv("GEMINI_API_KEY")
        init_gemini_api(api_key=api_key)
        
        # 2. åŠ è½½åˆ†ç±»æç¤ºè¯
        print("\nğŸ“– æ­¥éª¤ 2: åŠ è½½åˆ†ç±»æç¤ºè¯")
        classification_prompt = load_classification_prompt()
        
        # 3. åŠ è½½æºæ•°æ®
        print("\nğŸ“‚ æ­¥éª¤ 3: åŠ è½½æºæ•°æ®")
        source_data = load_source_data()
        total_items = len(source_data)
        
        # 4. åˆ†æ‰¹å¤„ç†
        print(f"\nğŸ”§ æ­¥éª¤ 4: å‡†å¤‡åˆ†æ‰¹å¤„ç†")
        num_batches = (total_items + BATCH_SIZE - 1) // BATCH_SIZE
        print(f"âœ… æ€»å…± {total_items} æ¡æ•°æ®ï¼Œå°†åˆ†ä¸º {num_batches} æ‰¹å¤„ç†")
        print(f"   æ¯æ‰¹å¤„ç† {BATCH_SIZE} æ¡æ•°æ®")
        
        # 5. è°ƒç”¨ Gemini è¿›è¡Œåˆ†ç±»ï¼ˆåˆ†æ‰¹ï¼‰
        print("\nğŸ¤– æ­¥éª¤ 5: è°ƒç”¨ Gemini æ¨¡å‹è¿›è¡Œåˆ†ç±»")
        print("=" * 80)
        
        all_results = []
        
        for batch_idx in range(num_batches):
            start_idx = batch_idx * BATCH_SIZE
            end_idx = min(start_idx + BATCH_SIZE, total_items)
            batch_data = source_data[start_idx:end_idx]
            
            print(f"\nğŸ“¦ æ‰¹æ¬¡ {batch_idx + 1}/{num_batches}")
            print(f"   å¤„ç†ç¬¬ {start_idx + 1} åˆ° {end_idx} æ¡æ•°æ® (å…± {len(batch_data)} æ¡)")
            
            # å‡†å¤‡è¿™ä¸€æ‰¹çš„è¾“å…¥æ•°æ®
            input_data = prepare_input_for_gemini(batch_data)
            
            # è°ƒç”¨ Gemini
            try:
                batch_result = classify_with_gemini(classification_prompt, input_data)
                all_results.append(batch_result)
                print(f"   âœ… æ‰¹æ¬¡ {batch_idx + 1} å®Œæˆ")
            except Exception as e:
                print(f"   âŒ æ‰¹æ¬¡ {batch_idx + 1} å¤±è´¥: {e}")
                print(f"   âš ï¸  å°†ç»§ç»­å¤„ç†ä¸‹ä¸€æ‰¹...")
                # æ·»åŠ ä¸€ä¸ªç©ºç»“æœï¼Œé¿å…ä¸­æ–­æ•´ä¸ªæµç¨‹
                all_results.append({})
            
            # æ‰¹æ¬¡ä¹‹é—´ç¨ä½œå»¶è¿Ÿï¼Œé¿å…è§¦å‘ API é™æµ
            if batch_idx < num_batches - 1:
                import time
                print(f"   â³ ç­‰å¾… 2 ç§’åç»§ç»­...")
                time.sleep(2)
        
        # 6. åˆå¹¶ç»“æœ
        print("\nğŸ”— æ­¥éª¤ 6: åˆå¹¶åˆ†ç±»ç»“æœ")
        final_result = merge_classification_results(all_results)
        print(f"âœ… å·²åˆå¹¶ {len(all_results)} ä¸ªæ‰¹æ¬¡çš„ç»“æœ")
        
        # 7. ä¿å­˜ç»“æœ
        print("\nğŸ’¾ æ­¥éª¤ 7: ä¿å­˜åˆ†ç±»ç»“æœ")
        save_result(final_result)
        
        print("\n" + "=" * 80)
        print("ğŸ‰ åˆ†ç±»å®Œæˆï¼")
        print("=" * 80)
    
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())

